## Scope:
After the computer boom of the 2000s, the number of people using personal
machines grew exponentially. Unfortunately, so did the number of malware trying to

Malware Classification and Defence Against Adversarial Attacks 2
hack into these machines to do various malicious tasks. Moreover, if we take a look at
todayâ€™s online landscape, we can easily see a number of malware trying to infect our
systems, held out by many security systems in place. These security systems not only
use hashes to verify if a software is malware or not, but also are starting to use
machine learning models to classify them. These machine learning models give us
the probability of a software being malicious, and if it is above a certain threshold,
then the user is notified of the same.
Unfortunately, as machine learning started to weed out malicious code, hackers
came up with a different technology. By using adversarial examples, hackers ensured
that the model was trained in such a way that the number of false positives would be
increased. This essentially confuses the model, and it allows harmful code to be
executed by the system. This is the problem that we have solved in this research
paper.
Firstly, we have compiled a dataset that comprises numerous features of 5000 data
samples. These samples were then fed into a machine learning model using several
existing algorithms and found out the best of them. Further, we have identified the
features that prominently impact the classification of the software. Using these
features and the model, we created a hybrid classifier that was able to classify
malware samples with greater accuracy as compared to existing algorithms.
Lastly, we fed the model adversarial examples. This caused the accuracy to fall, as
predicted. However, after training the model against such adversarial examples, our
model became better at dealing with potential obfuscations in the features on which
it was trained.
This paper is structured such that in Section 2, we
